---
layout: post
title: Bayesian Optimalities
categories: [Bayesian Theory]
---

I'm sometimes asked in conferences and meetings around Montreal: why Bayes?

This always strikes me. I do sometimes identify with "bayesianism", because I want to do research related to Bayesian statistics, but I don't feel that I'm a Bayesian in the sense that I adhere to one particular school of thought. First and foremost, I am a mathematician and a statistician. I want to understand the world through simulation and modelling, with the certainty provided by mathematical lenses, and I want to understand and develop the statistical tools that we use to understand the world when certainty is not at reach. That's my scientific identity.

Yet I'm also driven to answer: what else? What else than probabilities to model randomness and uncertainty? What else than probabilistic conditioning to account for new information? (I'm exagerating a bit here. There are tons of fun "elses" to answer these questions, but Bayes certainly stands out in the lot.) I'm drawn to Bayes stats because, more often than not, it's about providing meaningful answers to the questions that we really care about. I want, when possible, posterior probabilities of hypotheses; not 0-1 decisions and wishful thinking.

That's for the "let's infer stuff" part. In a prediction or point estimation context, I can also try to explain how Bayesian procedures are well suited to hierarchical modelling and convenient computational algorithms, how they can be used to incorporate prior information, have nice properties and follow conceptually clear principles which are well suited to mathematical analysis. They may or may not help solving a particular problem and that's perfectly fine, but they are still a subject of study worthwhile of specialisation.

This post is about some of these nice properties of posterior distributions that I like to talk about. I'll leave the non-nice things for another time!

## 1. Point estimation and minimal expected risk

## 2. Randomised estimation and minimal divergence

## 3. Online learning and minimal regret

## 4. Model selection, adaptability and oracle property